# 计算机网络

计算机网络的组成：

+ 边缘部分：这个部分由所有连接在互联网上的**主机**组成。边缘部分由**用户**直接使用，用来进行通信（传输数据、音频或视频）和资源共享。
+ 核心部分：这个部分由**大量网络**和连接这些网络的**路由器**组成。这部分为边缘部分提供服务（提供连通性和交换）。

---

## 边缘部分

主要涉及计算机之间的通信。指主机A的某一个进程和主机B上的另一个进程进行通信。通信方式有两类：

+ 客户-服务器方式（C/S方式）：**客户是服务请求方，服务器是服务提供方。**

  + A是客户端，运行**客户端程序**；B是服务器端，运行**服务器程序**。
  + A向B发出服务请求；B向A提供服务。

  ![img](https://i.loli.net/2021/07/14/yNUji1rvT9JLlB2.png)

+ 对等方式（P2P方式）

  是指两台主机在通信时并不区分哪一个是服务请求方哪一个是服务提供方。只要两台主机都运行了对等连接软件（P2P软件），他们就可以进行对等连接通信。这时，双方都可以下载对方硬盘中的共享文档。实际上在P2P方式中，每台主机既是客户，又是服务器。

----

## 核心部分

在网络核心部分作用的是**路由器(router)**。它是一种专用计算机，路由器是实现分组交换(packet  switching)的关键构建，其任务是转发收到的**分组**。

## 路由器的作用

路由器就是用来**转发分组**的，即进行分组交换。路由器收到一个分组，先**暂时存储一下，检查其首部，查找转发表**，按照首部中的目的地址，找到合适的接口转发出去，把分组交给下一个路由器。这样一步一步地存储转发的方式，把分组交付给最终的目的主机。

## 交换机的作用

记录接入主机的mac地址，出厂前写死，全球唯一。

通过网线(内部有至少4根线工作)，全双工数据交换。

但是有限机子交换，且必须是有线连接。只适合局域网。

如图，1-3通过**交换机**作用。网络1和网络2通过**路由器**作用。

![image-20210719105645580](https://i.loli.net/2021/07/19/QpV8BY2X4PTfgq6.png)

# 分组交换

电话以前是人工改变电路接线，现在是交换机。

![img](https://i.loli.net/2021/07/14/oKkrYp5vOuXiF7B.png)

## 交换

从通信资源的分配角度来看，**交换（switching）**就是按照某种方式动态地分配传输线路的资源。当用户打电话时，拨号请求建立连接。被叫用户接通后，主叫端和被叫端就建立了一条连接，也就是一条专用的物理通路。这就算是为当前的用户申请了通话所需的电信资源。通话完毕后，再释放掉资源。当资源不够时，主叫用户就会听到忙音，等待一段时间后再拨号。这就是**电路交换。**

## 常见交换方式

- 电路交换——整个报文的比特流连续地从一端到目的端。(传输大量数据)
- 报文交换——整个报文先传送到相邻结点，全部存储下来后查找转发表，转发到下一个结点。
- 分组交换——单个分组（报文一部分）传送到相邻结点，存储下来后查找转发表，转发到下一个结点。

## 分组交换

分组交换采用存储转发技术，把一个**报文**划分为几个**分组**后再进行传送。我们把要发送的整块数据称为一个**报文**（message）。在发送报文之前，先把较长的报文划分称为一个个更小的等长数据段，例如，每个数据段为1024bit。在每一个数据段前面，加上一些必要的控制信息组成**首部（header）**，就构成了一个**分组（packet）**。

分组又称为**“包”**，而分组的首部也称**“包头”**。分组是互联网传送的数据单元。

分组的首部非常重要，包含了**目的地址和源地址**等重要控制信息，这样每一个分组才能在互联网中独立地选择传输路径，并被正确地交付到分组传输的终点。

## 分组交换的优缺点

**优点：**

（1）高效，在分组传输时动态分配带宽，对通信链路逐段占用。

（2）灵活，为每一个分组独立地选择最合适的转发路由。

（3）迅速，以分组为单位，可以不先建立连接就能向主机发送数据。

（4）可靠，分布式多路由的分组交换网，使传输鲁棒性强。

**缺点：**

（1）分组在路由器存储转发时需要排队，有时延。

（2）分组必须携带控制信息（头部）也造成了开销。

# 计算机网络分类

+ 广域网WAN
+ 城域网MAN
+ 局域网LAN

# 计算机性能指标

1. 速率：每秒传输的数据来。单位为bit/s
2. 带宽：在单位时间内网络中某信道所通过的**最高数据率**
3. 吞吐量：单位时间内通过某个网络的实际的数据量。
4. 时延：数据从网络一端传送到另一端的时间。

# 计算机网络的结构模型

+ OSI体系结构
+ TCP/IP四层体系结构
+ 五层协议体系结构

## TCP/IP 4层

+ 网络接口层（网络驱动程序）；

+ 网络层：网络连接；

+ 传输层：通信，传递数据。

+ 应用层负责处理上层应用程序。

---

在**应用层**的数据称为**报文（message）**；在**传输层**的数据称为**段（segment）**；在**网络层**的数据叫 **分组包（packet）**，**网络接口层（链路层）**的数据称为**帧（frame）**。

## TCP/IP怎么传数据

![img](https://uploadfiles.nowcoder.com/images/20210329/675098158_1617019931089/586E508F161F26CE94633729AC56C602)

假定主机1的应用进程AP1向主机2的应用进程AP2传送数据。AP1先将数据交给本主机的第5层（应用层）。第5层加上必要的**控制信息**H5然后就成了下一层的**数据单元**。第4层（传输层）收到这个数据单元后，加上本层的控制信息H4，再交给第3层（网络层），成为第3层的数据单元。以此类推。不过到了第2层（数据链路层）后，控制信息被分成两部分，分别加到本层数据单元的**首部（H2）和尾部（T2）**；而第1层（物理层）由于是比特流的传输，所以不再加控制信息。比特流从首部开始传送。

当这一串的比特流离开主机1到达路由器时，就从路由器的第1层依次上升到第3层。每一层都根据控制信息进行必要的操作，然后将控制信息除去，将剩下的数据单元上交给上一层。当分组上升到第3层时，就根据首部中的目的地址查找路由器中的转发表，找出转发分组的接口，接下来往下传送到第2层，加上新的首部和尾部后，再到最下面的第1层，将比特流发送出去。

当这串比特流到达目的主机2时，就从第1层按照上面讲的方式，依次上升到第5层。最后，把应用进程AP1发送的数据交给目的主机AP2。

## OSI 7层模型

![img](https://uploadfiles.nowcoder.com/images/20210329/675098158_1617019888021/BA6BEB7AE28EF0A97D7A0A038FEB5060)

# TCP/IP 协议

## 说说TCP/IP四层分层模型，每个分层说两个协议

1. **应用层**：应用层是体系结构中的最高层。其任务是**通过应用进程间的交互来完成特定网络应用**。应用层协议定义了**应用进程间通信和交互的规则**。

   常用应用层协议如：

   域名系统**DNS**：DNS协议是用来将域名转换为IP地址（也可以将IP地址转换为相应的域名地址）。

   支持互联网应用的协议**HTTP**：超文本传输协议，在浏览器与服务器间传送文档。

   **SMTP**协议：简单邮件传送协议

   **FTP**协议：文件传输协议

   **RIP** 协议：距离矢量路由选择协议。

2. **传输层**：也称运输层。其任务是为**两台主机中进程之间的通信**提供**通用的数据传输服务**。

   主要有两种协议：

   **TCP：**提供面向连接的、可靠的数据传输服务。

   **UDP：**提供无连接的、尽最大努力可靠交付的传输服务。

   **SCTP** (Stream Control Transmission Protocol)是一种传输协议，在TCP/IP协议栈中所处的位置和TCP、UDP类似，兼有TCP/UDP两者特征。

3. **网络层**：其**任务是负责为分组交换网上的不同主机提供通信服务**。

   常用协议如：

   **IP** 协议：（1） 寻址。（2） 路由选择。（3） 分段与组装。

   **ICMP**协议：用于在IP主机、路由器之间传递控制消息，用来提供网络诊断信息 。

4. **网络接口层（链路层）**：两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要专门的链路层协议。

   **ARP**协议：ARP地址解析协议用于将计算机的网络地址（IP地址32位）转化为物理地址（MAC地址48位）

   **RARP**协议：RARP协议（Reverse ARP，反向ARP协议），其功能是将MAC地址解析为对应的IP地址。

# TCP和UDP的区别

（1）TCP需要建立一对一稳定连接；UDP无连接

（2）TCP一对一；UDP可以一对一、一对多、多对多

（3）TCP可靠传输，序列号、确认应答、超时重传；UDP不保证可靠传输，尽最大努力交付

（4）TCP头部字节20字节；UDP8个字节

（5）TCP开销大；UDP灵活开销小

（6）TCP提供可靠的服务，适用于通讯质量要求高的场景；UDP传输效率高，适用于高速传输和实时性要求的场景。

## TCP为什么要三次握手

客户端向服务器发送含有同步序列号的数据段给服务器，请求建立连接。

服务器收到客户端请求后，发送一个含有确认应答（ACK）和同步序列号（SYN）的数据段给客户端

客户端收到数据段后，再发送一个确认应答，确认已收到主机B 的数据段

## 为什么不能二次握手

主要为了防止已失效的连接请求报文段突然又传送到了B，B一致等待A发送数据，浪费资源。

##  为什么服务端易受到SYN攻击？

答：SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server则回复确认包，并等待Client确认，由于源地址不存在，因此Server需要不断重发直至超时，这些伪造的SYN包将长时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络拥塞甚至系统瘫痪。

防范SYN攻击措施：降低主机的等待时间使主机尽快的释放半连接的占用，短时间受到某IP的重复SYN则丢弃后续请求。

## TCP为什么要四次挥手

​    （1） TCP客户端发送一个FIN，用来关闭客户端到服务器的数据传送。

（2） 服务器收到这个FIN，它发回一个ACK， 

（3） 服务器关闭客户端的连接，发送一个FIN给客户端。

（4） 客户端发回ACK报文确认。

## TCP能三次挥手吗

不能三次。

第二次挥手和第三次挥手不能合并在一起，这是因为第二次挥手后，服务器端可能还在传输数据，需要等待数据传输完毕后再进行第三次挥手。

# 如何应对短连接、高并发的场景

1. 针对于大量短连接同时高并发的情况：
   最常用的一个手段就是优化主机系统设置。

   （1）比如**降低SYN timeout时间**，使得主机尽快释放半连接的占用。

   （2）或者采用**SYN cookie设置**，就是给每一个请求连接的IP地址分配一个Cookie，如果短时间内连续受到某个IP的重复SYN报文，就认定是受到了攻击，以后从这个IP地址来的包会被丢弃。Cookie是当浏览某网站时，由Web服务器置于硬盘上一个非常小的文本文件，用来记录用户ID，密码，浏览过的网页，停留时间等信息。当我们认为受到了攻击，合理的采用***设置等外部网络进行拦截。

   （3）**使用长连接**。在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的 TCP连接不会关闭，如果客户端再次访问这个服务器上的网页，会继续使用这一条已经建立的连接。

2. 而针对于**服务器高并发**的场景，有以下处理手段：
   （1）采用多IO复用模型，如select、epoll，甚至采用异步IO

   （2）采用队列进行削峰、缓存

   （3）采用多服务器负载均衡手段

   （4）数据库层面我们可以采用分库分表、读写分离等措施。

   （5）还可以采用缓存的方式

# TCP的可靠机制

**TCP保证可靠性**：

1. **序列号、确认应答、超时重传**
   数据到达接收方，接收方需要发出一个确认应答，表示已经收到该数据段，并且确认序列号，序列号说明了它下一次需要接收的数据序列号，保证数据传输有序。如果发送方迟迟未收到确认应答，那么可能是发送的数据丢失，也可能是确认应答丢失，这时发送方在等待一段时间后进行重传。

2. **窗口控制**
   TCP会利用窗口控制来提高传输速度，意思是在一个窗口大小内，不用一定等到应答才能发送下一段数据，窗口大小就是无需等待确认而可以继续发送数据的最大值。如果不使用窗口控制，每一个没收到确认应答的数据都要重发。
   使用窗口控制，如果数据段1001-2000丢失，后面数据每次传输，确认应答都会不停发送序号为1001的应答，表示我要接收1001开始的数据，发送端如果收到3次相同应答，就会立刻进行重发；数据一旦丢失，接收端会一直提醒。

3. **拥塞控制**
   如果把窗口定的很大，发送端连续发送大量的数据，可能造成网络的拥堵。为了防止拥堵，进行拥塞控制。

   （1）**慢启动**：定义拥塞窗口，一开始将该窗口大小设为1，之后每次收到一次确认应答，将拥塞窗口大小*2

   （2）**拥塞避免**：设置慢启动阈值，一般开始都设为65536。拥塞避免是只当拥塞窗口大小达到这个阈值，拥塞窗口的值不再指数上升，而是+1

   （3）**快恢复**：将报文段的超时重传看做拥塞，则一旦发生超时重传，我们就将阈值设为当前窗口大小的一半，并且窗口大小变为1，重新进入慢启动过程

   （4）**快速重传**：3次重复确认应答，立即重传。

# 什么是负载均衡

1. 当一台服务器的单位时间内的访问量越大时，服务器压力就越大，大到超过自身承受能力时，服务器就会崩溃。为了避免服务器崩溃，让用户有更好的体验，我们通过负载均衡的方式来分担服务器压力。
   **什么是负载均衡**：我们可以建立很多很多服务器，组成一个服务器集群，当用户访问网站时，先访问一个中间服务器，再让这个中间服务器在服务器集群中选择一个压力较小的服务器，然后将该访问请求引入该服务器。如此以来，用户的每次访问，都会保证服务器集群中的每个服务器压力趋于平衡，分担了服务器压力，避免了服务器崩溃的情况。
   **负载均衡有几种方式实现**
   （1）轮询（默认）
   请求依次轮流往每个应用服务器上进行分配，分配策略比较简单。
   缺点：不均匀，可能会出现，某些服务器接受的请求较重，负载压力重，有些负荷小，不可控。另外服务器之间需要进行session同步。
   （2）权重轮询（权重越高，进入的几率越大）
   优点：可以根据情况进行调整。可控，仍然需要进行session同步。
   （3）IP-Hash
   优点：采用hash的方式来映射服务器。无需进行session同步，固定IP会固定访问一台服务器。
   缺点：恶意攻击，会造成某台服务器压垮。提供的服务不同，面向的地区不同，IP可能会出现集中，造成不均匀，不可控。
   （4）Fair
   这种相当于自适应，会根据服务器处理请求的速度进行负载均衡分配。处理请求最早结束的，拿到下一个请求。看上去是不是很好。但是一般都不使用，说是考虑到网络不稳定因素。还有待研究。这种也需要进行session同步。
   （5）URL-Hash
   这种是根据URL进行hash，这样某些请求永远打某台服务器。利于利用服务器的缓存，但是可能由于URL的哈希值分布不均匀，以及业务侧重造成某些服务器压力大，某些负荷低。这种也需要进行session同步。

# Session和cookie的区别

由于HTTP是一种无状态协议,服务器没有办法单单从网络连接上面知道访问者的身份,为了解决这个问题,就诞生了Cookie

Cookie实际上是一小段的文本信息。客户端请求服务器，如果服务器需要记录该用户状态，就使用response向客户端浏览器颁发一个Cookie

客户端浏览器会把Cookie保存起来。当浏览器再请求该网站时，浏览器把请求的网址连同该Cookie一同提交给服务器。服务器检查该Cookie，以此来辨认用户状态。服务器还可以根据需要修改Cookie的内容。

实际就是颁发一个通行证，每人一个，无论谁访问都必须携带自己通行证。这样服务器就能从通行证上确认客户身份了。这就是Cookie的工作原理

cookie 可以让服务端程序跟踪每个客户端的访问，但是每次客户端的访问都必须传回这些Cookie，如果 Cookie 很多，这无形地增加了客户端与服务端的数据传输量，

而 Session 的出现正是为了解决这个问题。同一个客户端每次和服务端交互时，不需要每次都传回所有的 Cookie 值，而是只要传回一个 ID，这个 ID 是客户端第一次访问服务器的时候生成的， 而且每个客户端是唯一的。这样每个客户端就有了一个唯一的 ID，客户端只要传回这个 ID 就行了，这个 ID 通常是 NANE 为JSESIONID 的一个 Cookie。
**区别**：

1、数据存放位置不同：cookie数据存放在客户的浏览器上，session数据放在服务器上。

2、安全程度不同：cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗,考虑到安全应当使用session。

3、性能使用程度不同：session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能,考虑到减轻服务器性能方面，应当使用cookie。

4、数据存储大小不同：单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie，而session则存储与服务端，浏览器对其没有限制。
5、会话机制不同
session会话机制：session会话机制是一种服务器端机制，它使用类似于哈希表（可能还有哈希表）的结构来保存信息。

cookies会话机制：cookie是服务器存储在本地计算机上的小块文本，并随每个请求发送到同一服务器。 Web服务器使用HTTP标头将cookie发送到客户端。在客户端终端，浏览器解析cookie并将其保存为本地文件，该文件自动将来自同一服务器的任何请求绑定到这些cookie。

# 网络调试的工具

1. Ping命令：ping属于一个通信协议，是TCP/IP协议的一部分。利用“ping”命令可以检查网络是否通畅或者网络连接速度，很好地分析和判定网络故障。
   **它的原理是**：利用网络上机器IP地址的唯一性，给目标IP地址发送一个数据包，通过对方回复的数据包来确定两台网络机器是否连接相通，时延是多少。
2. Nslookup(name server lookup)是一个用于查询因特网域名信息或诊断DNS 服务器问题的工具.

# socket网络编程

## 网络中的进程如何唯一标识

三元组（IP地址、协议、端口）

# 什么是TCP粘包现象

在socket网络程序中，

1. 发送端为了将多个发往接收端的包，更有效的发到对方，使用了优化方法（**Nagle算法**），将多次间隔较小、数据量小的数据，合并成一个大的数据块，然后进行**封包**。
2. 或者接收端接收不及时，造成TCP缓冲区中存放多段数据。

这两种情况都会出现TCP粘包问题。

## 如何解决

科学**封包和解包**。